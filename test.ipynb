{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\freelancer\\student ocr\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0         1    2         3        4         5    6\n",
      "0   No.  Obtained  No.  Obtained    3.000  Obtained  NaN\n",
      "1     1              9                 17        IN  NaN\n",
      "2     2         0   10                 15            NaN\n",
      "3     0             11         1       19        22    /\n",
      "4     4    3uiken   12                  1            NaN\n",
      "5     5             13         !        d            NaN\n",
      "6     6             14                 22            NaN\n",
      "7     7             15                 23            NaN\n",
      "8  Wazo         e  dyd       udz  24/1200    95asit  NaN\n",
      "     0         1    2         3    4         5      6\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained  Marks\n",
      "1    1         o    9             17              NaN\n",
      "2    2         2   10             18              NaN\n",
      "3    3         4   11             19              NaN\n",
      "4    4         5   12             20              NaN\n",
      "5    5         .   13             21              NaN\n",
      "6    6         1   14             22              NaN\n",
      "7    7       3-5   15             23              NaN\n",
      "8    8         5   16             24              NaN\n",
      "     0         1    2         3    4 5         6\n",
      "0  No.  Obtained  No.  Obtained  No.    Obtained\n",
      "1    1              9             17         NaN\n",
      "2    2         2   10             18         NaN\n",
      "3    3             11             19         NaN\n",
      "4              5   12             20         NaN\n",
      "5    5         1   13             21         NaN\n",
      "6    6         2   14             22         NaN\n",
      "7    7             15             23         NaN\n",
      "8    8             16             24         NaN\n",
      "     0         1    2         3    4      5         6\n",
      "0  No.  Obtained  No.  Obtained  No.  Marks  Obtained\n",
      "1    1         0    9             17              NaN\n",
      "2    2             10             18              NaN\n",
      "3    3         0   11             19              NaN\n",
      "4    4         2   12             20              NaN\n",
      "5    5         6   13             21              NaN\n",
      "6    6         2   14             22              NaN\n",
      "7    7         1   15             23              NaN\n",
      "8    8       2.5   16             24              NaN\n",
      "     0         1    2         3    4         5      6\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained  Marks\n",
      "1    1         2    9             17              NaN\n",
      "2    2         1   10             18              NaN\n",
      "3    3         1   11             19              NaN\n",
      "4    4         2   12             20              NaN\n",
      "5    5         3   13             21              NaN\n",
      "6    6             14             22              NaN\n",
      "7    7             15             23              NaN\n",
      "8    8         5   16             24              NaN\n",
      "     0         1    2         3    4      5         6\n",
      "0  No.  Obtained  No.  Obtained  No.  Marks  Obtained\n",
      "1    1        IS    9             17              NaN\n",
      "2    2             10             18              NaN\n",
      "3    o             11             19              NaN\n",
      "4    4         4   12             20              NaN\n",
      "5    5         ऽ   13             21              NaN\n",
      "6    6       0.5   14             22              NaN\n",
      "7    7       0.8   15             23              NaN\n",
      "8    8             16             24              NaN\n",
      "     0         1    2         3    4      5         6\n",
      "0  No.  Obtained  No.  Obtained  No.  Marks  Obtained\n",
      "1    1         3    9             17              NaN\n",
      "2    2         .   10             18              NaN\n",
      "3    3         .   11             19              NaN\n",
      "4              5   12             20              NaN\n",
      "5    5         .   13             21              NaN\n",
      "6    6       1.5   14             22              NaN\n",
      "7    7             15             23              NaN\n",
      "8    8             16             24              NaN\n",
      "     0         1    2         3    4         5      6\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained  Marks\n",
      "1    1         .    9             17              NaN\n",
      "2    2         .   10             18              NaN\n",
      "3    3       4.5   11             19              NaN\n",
      "4    4         5   12             20              NaN\n",
      "5    5       3.5   13             21              NaN\n",
      "6    6         5   14             22              NaN\n",
      "7    7             15             23              NaN\n",
      "8    8         \"   16             24              NaN\n",
      "     0         1    2         3    4      5         6\n",
      "0  No.  Obtained  No.  Obtained  No.  Marks  Obtained\n",
      "1   pa         3    9             17              NaN\n",
      "2    2         .   10             18              NaN\n",
      "3    3             11             19              NaN\n",
      "4    4         .   12             20              NaN\n",
      "5    5       3.5   13             21              NaN\n",
      "6    6        Si   14             22              NaN\n",
      "7    7      lifl   15             23              NaN\n",
      "8    8         ऽ   16             24              NaN\n",
      "     0         1    2         3    4      5         6\n",
      "0  No.  Obtained  No.  Obtained  No.  Marks  Obtained\n",
      "1    1         5    9             17              NaN\n",
      "2    2         1   10             18              NaN\n",
      "3    3         2   11             19              NaN\n",
      "4    4         3   12             20              NaN\n",
      "5    5         5   13             21              NaN\n",
      "6    6             14             22              NaN\n",
      "7    7       2-2   15             23              NaN\n",
      "8    8         5   16             24              NaN\n",
      "     0         1    2         3    4         5      6\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained  Marks\n",
      "1    1              9             17              NaN\n",
      "2    2         B   10             18              NaN\n",
      "3    3        24   11             19              NaN\n",
      "4    4        کی   12             20              NaN\n",
      "5    5         5   13             21              NaN\n",
      "6    6         5   14             22              NaN\n",
      "7    7             15             23              NaN\n",
      "8    8         S   16            124              NaN\n",
      "     0         1    2         3    4 5         6\n",
      "0  No.  Obtained  No.  Obtained  No.    Obtained\n",
      "1    1              9             17         NaN\n",
      "2    2         ♥   10             18         NaN\n",
      "3    3         3   11             19         NaN\n",
      "4    4         3   12             20         NaN\n",
      "5    5             13             21         NaN\n",
      "6    6       1.5   14             22         NaN\n",
      "7    7             15             23         NaN\n",
      "8   84       0.5   16             24         NaN\n",
      "     0         1    2         3    4         5      6\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained  Marks\n",
      "1    1         5    9             17              NaN\n",
      "2    2         .   10             18              NaN\n",
      "3    3         .   11             19              NaN\n",
      "4    4         5   12             20              NaN\n",
      "5    5         .   13             21              NaN\n",
      "6    6         2   14             22              NaN\n",
      "7    7             15             23              NaN\n",
      "8    8         .   16             24              NaN\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "net = cv2.dnn.readNetFromONNX(\"best.onnx\")\n",
    "file = open(\"coco.txt\", \"r\")\n",
    "classes = file.read().split('\\n')\n",
    "import os\n",
    "\n",
    "# Directory path where your images are located\n",
    "folder_path = \"../df\"\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# Filter the list to only include image files (e.g., .jpg, .png, .jpeg)\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.gif']  # Add more extensions if needed\n",
    "image_paths = [os.path.join(folder_path, file) for file in file_list if any(file.lower().endswith(ext) for ext in image_extensions)]\n",
    "  # Add the paths of the images you want to process\n",
    "\n",
    "for image_path in image_paths:\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    img_height, img_width = img.shape[:2]  # Get the height and width of the image\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, scalefactor=1/255, size=(640, 640), mean=[0, 0, 0], swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()[0]\n",
    "\n",
    "    # cx, cy, w, h, confidence, 80 class_scores\n",
    "    # class_ids, confidences, boxes\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    rows = detections.shape[0]\n",
    "\n",
    "    x_scale = img_width / 640\n",
    "    y_scale = img_height / 640\n",
    "\n",
    "    for i in range(rows):\n",
    "        row = detections[i]\n",
    "        confidence = row[4]\n",
    "        if confidence > 0.5:\n",
    "            class_scores = row[5:]\n",
    "            ind = np.argmax(class_scores)\n",
    "            if class_scores[ind] > 0.5:\n",
    "                class_ids.append(ind)\n",
    "                confidences.append(confidence)\n",
    "                cx, cy, w, h = row[:4]\n",
    "                x1 = int((cx - w / 2) * x_scale)\n",
    "                y1 = int((cy - h / 2) * y_scale)\n",
    "                width = int(w * x_scale)\n",
    "                height = int(h * y_scale)\n",
    "                box = np.array([x1, y1, width, height])\n",
    "                boxes.append(box)\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.5)\n",
    "\n",
    "    for i in indices:\n",
    "        x1, y1, w, h = boxes[i]\n",
    "        label = classes[class_ids[i]]\n",
    "        conf = confidences[i]\n",
    "        text = label + \" {:.2f}\".format(conf)\n",
    "\n",
    "        # Crop the detection region\n",
    "        crop_img = img[y1:y1+h, x1:x1+w]\n",
    "\n",
    "        # Save cropped image with the respective class name\n",
    "        save_path = f\"{label}.jpg\"\n",
    "        cv2.imwrite(save_path, crop_img)\n",
    "\n",
    "        cv2.rectangle(img, (x1, y1), (x1 + w, y1 + h), (255, 0, 0), 2)\n",
    "        cv2.putText(img, text, (x1, y1 - 2), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255, 0, 255), 2)\n",
    "\n",
    "    cv2.imwrite('my.jpg',img)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    # Load an image\n",
    "    image = cv2.imread('b.jpg')\n",
    "\n",
    "    # Create a sharpening kernel\n",
    "    sharpening_kernel = np.array([[-1, -1, -1],\n",
    "                                [-1,  9, -1],\n",
    "                                [-1, -1, -1]])\n",
    "\n",
    "    # Apply the convolution to sharpen the image\n",
    "    sharpened_image = cv2.filter2D(image, -1, sharpening_kernel)\n",
    "\n",
    "    # Display the original and sharpened images\n",
    "\n",
    "    cv2.imwrite('b.jpg', sharpened_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    import io\n",
    "    import os\n",
    "\n",
    "    from google.cloud import vision\n",
    "    from google.cloud.vision_v1 import types\n",
    "\n",
    "    # Set your environment variable for your GCP credentials\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'circular-genius-402810-13afeaaa2b14.json'\n",
    "\n",
    "    # Initialize the Vision API client\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # Load the image\n",
    "    with io.open('b.jpg', 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    # Create the text detection request\n",
    "    request = types.AnnotateImageRequest(\n",
    "        image=image,\n",
    "        features=[types.Feature(type='TEXT_DETECTION')]\n",
    "    )\n",
    "\n",
    "    # Send the request and get the response\n",
    "    response = client.annotate_image(request)\n",
    "\n",
    "\n",
    "    import json\n",
    "    from google.protobuf.json_format import MessageToDict\n",
    "    response_dict = MessageToDict(response._pb)\n",
    "\n",
    "    # Access the textAnnotations\n",
    "    text_annotations = response_dict.get('textAnnotations', [])\n",
    "\n",
    "    # Function to calculate the center point of a bounding box\n",
    "    def calculate_center(vertices):\n",
    "        x_coordinates = [vertex['x'] for vertex in vertices]\n",
    "        y_coordinates = [vertex['y'] for vertex in vertices]\n",
    "        center_x = sum(x_coordinates) / len(vertices)\n",
    "        center_y = sum(y_coordinates) / len(vertices)\n",
    "        return center_x, center_y\n",
    "\n",
    "    # Calculate center points for all bounding boxes along with descriptions\n",
    "    center_points_with_descriptions = []\n",
    "    for annotation in text_annotations[1:]:\n",
    "        description = annotation.get('description', 'N/A')  # Use 'N/A' if description is not present\n",
    "        vertices = annotation['boundingPoly']['vertices']\n",
    "        center_x, center_y = calculate_center(vertices)\n",
    "        center_points_with_descriptions.append({'description': description, 'x': center_x, 'y': center_y})\n",
    "\n",
    "\n",
    "\n",
    "    data = center_points_with_descriptions\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Define the target number of rows in column 0\n",
    "    target_rows_in_col0 = 6\n",
    "    y_threshold = 40  # Start with the initial threshold\n",
    "\n",
    "    while True:\n",
    "        # Calculate the bins for x based on the number of columns\n",
    "        x_bins = np.linspace(df['x'].min(), df['x'].max(), target_rows_in_col0 + 1)\n",
    "\n",
    "        # Assign each point to a cell in the table\n",
    "        df['column'] = np.digitize(df['x'], x_bins) - 1\n",
    "\n",
    "        # Create 'y_bins' using the updated 'y_threshold'\n",
    "        y_bins = np.arange(df['y'].min(), df['y'].max() + y_threshold, y_threshold)\n",
    "\n",
    "        # Assign each point to a row in the table\n",
    "        df['row'] = np.digitize(df['y'], y_bins) - 1\n",
    "\n",
    "        # Calculate the number of unique rows in column 0\n",
    "        num_unique_rows_in_col0 = len(df[df['column'] == 0]['row'].unique())\n",
    "    \n",
    "        \n",
    "        # Calculate the number of rows dynamically based on the 'row' column\n",
    "        num_rows = df['row'].max() + 1\n",
    "\n",
    "        # Create a table with the specified number of rows and columns\n",
    "        table = pd.DataFrame('', index=np.arange(num_rows), columns=np.arange(target_rows_in_col0))\n",
    "\n",
    "        # Fill the table with the descriptions from the data\n",
    "        for i, row in df.iterrows():\n",
    "            table.at[row['row'], row['column']] = row['description']\n",
    "\n",
    "        # If the number of unique rows in column 0 matches the target, exit the loop\n",
    "        if table.shape[0] == 9:\n",
    "            break\n",
    "\n",
    "        # Increase the y_threshold for the next iteration\n",
    "        y_threshold += 10  # You can adjust the step as needed\n",
    "\n",
    "    # Calculate the number of rows dynamically based on the 'row' column\n",
    "    num_rows = df['row'].max() + 1\n",
    "\n",
    "    # Create a table with the specified number of rows and columns\n",
    "    table = pd.DataFrame('', index=np.arange(num_rows), columns=np.arange(target_rows_in_col0))\n",
    "\n",
    "    # Fill the table with the descriptions from the data\n",
    "    for i, row in df.iterrows():\n",
    "        table.at[row['row'], row['column']] = row['description']\n",
    "\n",
    "    # Print the resulting table\n",
    "    print(table)\n",
    "    table.columns = table.columns.astype(str)\n",
    "    table = table.drop(table.index[0])\n",
    "    df=table\n",
    "    new_df = df.replace('', np.nan)\n",
    "\n",
    "\n",
    "# change to your key \n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'circular-genius-402810-13afeaaa2b14.json'\n",
    "\n",
    "    # Initialize the Vision API client\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # Load the image\n",
    "    with io.open('a.jpg', 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    # Create the text detection request\n",
    "    request = types.AnnotateImageRequest(\n",
    "        image=image,\n",
    "        features=[types.Feature(type='TEXT_DETECTION')]\n",
    "    )\n",
    "\n",
    "    # Send the request and get the response\n",
    "    response = client.annotate_image(request)\n",
    "    text_annotations = response.text_annotations\n",
    "    import re\n",
    "    # Get the first text annotation (which contains the entire text)\n",
    "\n",
    "    full_text = text_annotations[0].description\n",
    "\n",
    "    digits = re.sub(r'\\D', '', full_text)\n",
    "\n",
    "\n",
    "    # Load the existing DataFrame from the CSV file\n",
    "    main_data = pd.read_csv('v.csv')\n",
    "\n",
    "    # Your list containing question numbers and marks\n",
    "    data_list = [digits] + list(new_df['1']) + list(new_df['3']) + list(new_df['5'])\n",
    "\n",
    "    # Create a new row as a DataFrame with the same column names as the main_data\n",
    "    new_row = pd.DataFrame([data_list], columns=main_data.columns)\n",
    "\n",
    "    # Concatenate the new row to the existing DataFrame\n",
    "    existing_df = pd.concat([main_data, new_row], ignore_index=True)\n",
    "    existing_df=existing_df.fillna(0)\n",
    "\n",
    "    # Save the updated DataFrame to the CSV file without creating new columns\n",
    "    existing_df.to_csv('v.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "\n",
    "# Set your environment variable for your GCP credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'circular-genius-402810-13afeaaa2b14.json'\n",
    "\n",
    "# Initialize the Vision API client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# Load the image\n",
    "with io.open('a.jpg', 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = types.Image(content=content)\n",
    "\n",
    "# Create the text detection request\n",
    "request = types.AnnotateImageRequest(\n",
    "    image=image,\n",
    "    features=[types.Feature(type='TEXT_DETECTION')]\n",
    ")\n",
    "\n",
    "# Send the request and get the response\n",
    "response = client.annotate_image(request)\n",
    "text_annotations = response.text_annotations\n",
    "import re\n",
    "# Get the first text annotation (which contains the entire text)\n",
    "\n",
    "full_text = text_annotations[0].description\n",
    "\n",
    "full_text = 'Enrolment No.:___220479'\n",
    "digits = re.sub(r'\\D', '', full_text)\n",
    "\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'220479'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Question Marks Question Diarks Question Marks\n",
      "No. Obtained\n",
      "No.\n",
      "Hobtained\n",
      "No. Obtained\n",
      "4\n",
      "19\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "11\n",
      "on\n",
      "5\n",
      "00\n",
      "16\n",
      "21st\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "Text: Question\n",
      "Text: Marks\n",
      "Text: Question\n",
      "Text: Diarks\n",
      "Text: Question\n",
      "Text: Marks\n",
      "Text: No.\n",
      "Text: Obtained\n",
      "Text: No.\n",
      "Text: Hobtained\n",
      "Text: No.\n",
      "Text: Obtained\n",
      "Text: 4\n",
      "Text: 19\n",
      "Text: 10\n",
      "Text: 11\n",
      "Text: 12\n",
      "Text: 13\n",
      "Text: 14\n",
      "Text: 11\n",
      "Text: on\n",
      "Text: 5\n",
      "Text: 00\n",
      "Text: 16\n",
      "Text: 21st\n",
      "Text: 18\n",
      "Text: 19\n",
      "Text: 20\n",
      "Text: 21\n",
      "Text: 22\n",
      "Text: 23\n",
      "Text: 24\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread('bc.jpg')\n",
    "\n",
    "# Create a sharpening kernel\n",
    "sharpening_kernel = np.array([[-1, -1, -1],\n",
    "                              [-1,  9, -1],\n",
    "                              [-1, -1, -1]])\n",
    "\n",
    "# Apply the convolution to sharpen the image\n",
    "sharpened_image = cv2.filter2D(image, -1, sharpening_kernel)\n",
    "\n",
    "# Display the original and sharpened images\n",
    "\n",
    "cv2.imwrite('bc.jpg', sharpened_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "\n",
    "# Set your environment variable for your GCP credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'circular-genius-402810-13afeaaa2b14.json'\n",
    "\n",
    "# Initialize the Vision API client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# Load the image\n",
    "with io.open('bc.jpg', 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = types.Image(content=content)\n",
    "\n",
    "# Create the text detection request\n",
    "request = types.AnnotateImageRequest(\n",
    "    image=image,\n",
    "    features=[types.Feature(type='TEXT_DETECTION')]\n",
    ")\n",
    "\n",
    "# Send the request and get the response\n",
    "response = client.annotate_image(request)\n",
    "g=[]\n",
    "for text_annotation in response.text_annotations:\n",
    "    print('Text:', text_annotation.description)\n",
    "    g.append(text_annotation.description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"description\": \"Question\",\n",
      "    \"x\": 77.0,\n",
      "    \"y\": 42.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Marks\",\n",
      "    \"x\": 230.5,\n",
      "    \"y\": 46.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Question\",\n",
      "    \"x\": 384.0,\n",
      "    \"y\": 46.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Diarks\",\n",
      "    \"x\": 534.0,\n",
      "    \"y\": 46.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Question\",\n",
      "    \"x\": 686.5,\n",
      "    \"y\": 46.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Marks\",\n",
      "    \"x\": 836.0,\n",
      "    \"y\": 46.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"No.\",\n",
      "    \"x\": 76.0,\n",
      "    \"y\": 81.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Obtained\",\n",
      "    \"x\": 232.0,\n",
      "    \"y\": 83.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"No.\",\n",
      "    \"x\": 384.0,\n",
      "    \"y\": 86.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Hobtained\",\n",
      "    \"x\": 528.5,\n",
      "    \"y\": 85.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"No.\",\n",
      "    \"x\": 687.0,\n",
      "    \"y\": 87.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Obtained\",\n",
      "    \"x\": 839.5,\n",
      "    \"y\": 87.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"4\",\n",
      "    \"x\": 234.0,\n",
      "    \"y\": 144.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"19\",\n",
      "    \"x\": 380.0,\n",
      "    \"y\": 153.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"10\",\n",
      "    \"x\": 383.0,\n",
      "    \"y\": 214.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"11\",\n",
      "    \"x\": 382.5,\n",
      "    \"y\": 273.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"12\",\n",
      "    \"x\": 383.0,\n",
      "    \"y\": 333.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"13\",\n",
      "    \"x\": 380.5,\n",
      "    \"y\": 395.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"14\",\n",
      "    \"x\": 379.5,\n",
      "    \"y\": 455.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"11\",\n",
      "    \"x\": 75.5,\n",
      "    \"y\": 150.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"on\",\n",
      "    \"x\": 73.5,\n",
      "    \"y\": 271.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"5\",\n",
      "    \"x\": 73.0,\n",
      "    \"y\": 393.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"00\",\n",
      "    \"x\": 67.5,\n",
      "    \"y\": 574.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"16\",\n",
      "    \"x\": 379.0,\n",
      "    \"y\": 578.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"21st\",\n",
      "    \"x\": 427.0,\n",
      "    \"y\": 201.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"18\",\n",
      "    \"x\": 686.0,\n",
      "    \"y\": 216.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"19\",\n",
      "    \"x\": 685.5,\n",
      "    \"y\": 275.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"20\",\n",
      "    \"x\": 684.5,\n",
      "    \"y\": 337.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"21\",\n",
      "    \"x\": 683.5,\n",
      "    \"y\": 397.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"22\",\n",
      "    \"x\": 683.5,\n",
      "    \"y\": 458.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"23\",\n",
      "    \"x\": 683.5,\n",
      "    \"y\": 517.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"24\",\n",
      "    \"x\": 682.5,\n",
      "    \"y\": 580.0\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "response_dict = MessageToDict(response._pb)\n",
    "\n",
    "# Access the textAnnotations\n",
    "text_annotations = response_dict.get('textAnnotations', [])\n",
    "\n",
    "# Function to calculate the center point of a bounding box\n",
    "def calculate_center(vertices):\n",
    "    x_coordinates = [vertex['x'] for vertex in vertices]\n",
    "    y_coordinates = [vertex['y'] for vertex in vertices]\n",
    "    center_x = sum(x_coordinates) / len(vertices)\n",
    "    center_y = sum(y_coordinates) / len(vertices)\n",
    "    return center_x, center_y\n",
    "\n",
    "# Calculate center points for all bounding boxes along with descriptions\n",
    "center_points_with_descriptions = []\n",
    "for annotation in text_annotations[1:]:\n",
    "    description = annotation.get('description', 'N/A')  # Use 'N/A' if description is not present\n",
    "    vertices = annotation['boundingPoly']['vertices']\n",
    "    center_x, center_y = calculate_center(vertices)\n",
    "    center_points_with_descriptions.append({'description': description, 'x': center_x, 'y': center_y})\n",
    "\n",
    "# Print the center points with descriptions\n",
    "print(json.dumps(center_points_with_descriptions, indent=2))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = center_points_with_descriptions\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a threshold for y values to consider them as belonging to the same row\n",
    "y_threshold = 50\n",
    "\n",
    "# Define the number of columns\n",
    "num_cols = 6\n",
    "\n",
    "# Calculate the bins for x based on the number of columns\n",
    "x_bins = np.linspace(df['x'].min(), df['x'].max(), num_cols + 1)\n",
    "\n",
    "# Assign each point to a cell in the table\n",
    "df['column'] = np.digitize(df['x'], x_bins) - 1\n",
    "\n",
    "# Create 'y_bins' using 'y_threshold'\n",
    "y_bins = np.arange(df['y'].min(), df['y'].max() + y_threshold, y_threshold)\n",
    "\n",
    "# Assign each point to a row in the table\n",
    "df['row'] = np.digitize(df['y'], y_bins) - 1\n",
    "\n",
    "# Calculate the number of rows dynamically based on the 'row' column\n",
    "num_rows = df['row'].max() + 1\n",
    "\n",
    "# Create a table with the specified number of rows and columns\n",
    "table = pd.DataFrame('', index=np.arange(num_rows), columns=np.arange(num_cols))\n",
    "\n",
    "# Fill the table with the descriptions from the data\n",
    "for i, row in df.iterrows():\n",
    "    table.at[row['row'], row['column']] = row['description']\n",
    "\n",
    "# Print the resulting table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0         1     2          3    4      5         6\n",
      "0   No.  Obtained   No.  Hobtained  No.  Marks  Obtained\n",
      "1                                                    NaN\n",
      "2    11         4    19                              NaN\n",
      "3                  21st              18              NaN\n",
      "4    on              11              19              NaN\n",
      "5                    12              20              NaN\n",
      "6                                                    NaN\n",
      "7     5              13              21              NaN\n",
      "8                    14              22              NaN\n",
      "9                                    23              NaN\n",
      "10   00              16              24              NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = center_points_with_descriptions\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a threshold for y values to consider them as belonging to the same row\n",
    "y_threshold = 50\n",
    "\n",
    "# Define the number of columns\n",
    "num_cols = 6\n",
    "\n",
    "# Calculate the bins for x based on the number of columns\n",
    "x_bins = np.linspace(df['x'].min(), df['x'].max(), num_cols + 1)\n",
    "\n",
    "# Assign each point to a cell in the table\n",
    "df['column'] = np.digitize(df['x'], x_bins) - 1\n",
    "\n",
    "# Create 'y_bins' using 'y_threshold'\n",
    "y_bins = np.arange(df['y'].min(), df['y'].max() + y_threshold, y_threshold)\n",
    "\n",
    "# Assign each point to a row in the table\n",
    "df['row'] = np.digitize(df['y'], y_bins) - 1\n",
    "\n",
    "# Calculate the number of rows dynamically based on the 'row' column\n",
    "num_rows = df['row'].max() + 1\n",
    "\n",
    "# Create a table with the specified number of rows and columns\n",
    "table = pd.DataFrame('', index=np.arange(num_rows), columns=np.arange(num_cols))\n",
    "\n",
    "# Fill the table with the descriptions from the data\n",
    "for i, row in df.iterrows():\n",
    "    table.at[row['row'], row['column']] = row['description']\n",
    "\n",
    "# Print the resulting table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# red image table \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image_path = 'b.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "    # Get the height and width of the image\n",
    "image_height, image_width, _ = image.shape\n",
    " # Height of the blank image\n",
    "blank_image = np.zeros((image_height, image_width, 3), np.uint8)\n",
    "\n",
    "# Draw circles and text on the blank image\n",
    "for point in center_points_with_descriptions:\n",
    "    x, y = int(point['x']), int(point['y'])\n",
    "    description = point['description']\n",
    "\n",
    "    # Draw text\n",
    "    cv2.putText(blank_image, description, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)  # Red text\n",
    "\n",
    "# Define the number of columns and draw vertical lines\n",
    "num_columns = 6  # Adjust this to match the number of columns in your data\n",
    "column_width = image_width // num_columns\n",
    "for i in range(1, num_columns):\n",
    "    x = i * column_width\n",
    "    cv2.line(blank_image, (x, 0), (x, image_height), (0, 0, 255), 2)  # Draw red vertical lines\n",
    "\n",
    "# Display or save the image\n",
    "cv2.imshow('Annotated Image', blank_image)\n",
    "cv2.waitKey(0)  # Wait until a key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image to a file\n",
    "cv2.imwrite('annotated_image.jpg', blank_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Example path, replace with your Tesseract path\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread('annotated_image.jpg')\n",
    "\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply adaptive thresholding to invert the image\n",
    "binary_thresh = cv2.adaptiveThreshold(~gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                      cv2.THRESH_BINARY, 15, -2)\n",
    "\n",
    "# Copy the binary image\n",
    "vertical = binary_thresh.copy()\n",
    "\n",
    "# Define the structure size for the vertical kernel\n",
    "vertical_size = vertical.shape[0] // 30\n",
    "\n",
    "# Create a vertical kernel\n",
    "vertical_structure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vertical_size))\n",
    "\n",
    "# Apply morphological operations\n",
    "vertical = cv2.erode(vertical, vertical_structure)\n",
    "vertical = cv2.dilate(vertical, vertical_structure)\n",
    "\n",
    "# Use pytesseract to extract text\n",
    "config = ('-l eng --oem 1 --psm 3')\n",
    "text = pytesseract.image_to_string(vertical)\n",
    "\n",
    "# Post-process the extracted text\n",
    "rows = text.split('\\n')\n",
    "table = [row.split() for row in rows]\n",
    "\n",
    "# Print the extracted table data\n",
    "for row in table:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Column1    Column2\n",
      "0   Question      Marks\n",
      "1        No.  Obtained}\n",
      "2          1         25\n",
      "3          2          3\n",
      "4          3         2.\n",
      "5          4          5\n",
      "6          5          5\n",
      "7          6         35\n",
      "8          7         45\n",
      "9        No,       None\n",
      "10        10       None\n",
      "11        Ww       None\n",
      "12        12       None\n",
      "13        13       None\n",
      "14        14       None\n",
      "15        15       None\n",
      "16        16       None\n",
      "17     Morks       None\n",
      "18    Obtait       None\n",
      "19  Question       None\n",
      "20       No.       None\n",
      "21        WW       None\n",
      "22        18       None\n",
      "23        19       None\n",
      "24         2       None\n",
      "25        24       None\n",
      "26     Morks       None\n",
      "27  Obtained       None\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Example path, replace with your Tesseract path\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread('annotated_image.jpg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding\n",
    "_, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find the contours\n",
    "contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter contours based on their area (you may need to adjust the value)\n",
    "contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 50]\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i, contour in enumerate(contours):\n",
    "    # Get the bounding rectangle for the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Slice the image using the bounding rectangle\n",
    "    roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "    # Extract text from the region of interest\n",
    "    text = pytesseract.image_to_string(roi)\n",
    "\n",
    "    # Split the text into lines and values\n",
    "    lines = text.splitlines()\n",
    "    values = [line.split() for line in lines if line.strip()]\n",
    "\n",
    "    # If values are less than expected, append None values to compensate\n",
    "    num_columns = len(values[0])  # Assuming the number of columns is the same for all rows\n",
    "    for value in values:\n",
    "        if len(value) < num_columns:\n",
    "            value += [None] * (num_columns - len(value))\n",
    "\n",
    "    # Append the values to the DataFrame\n",
    "    df_temp = pd.DataFrame(values, columns=[\"Column1\", \"Column2\"])\n",
    "    df = pd.concat([df, df_temp], ignore_index=True)\n",
    "\n",
    "# Specify the columns to keep (excluding the \"name\" column)\n",
    "columns_to_keep = [col for col in df.columns if col != 'name']\n",
    "\n",
    "# Create a new DataFrame with the desired columns\n",
    "df_cleaned = df[columns_to_keep]\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\freelancer\\student ocr\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
