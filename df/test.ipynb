{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Install the tesseract executable from https://github.com/tesseract-ocr/tesseract/wiki\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update this path\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('an2.png', 0)\n",
    "\n",
    "# Apply OCR to the entire image\n",
    "text = pytesseract.image_to_string(Image.fromarray(img))\n",
    "\n",
    "# Print the recognized text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectangle vertices: [(54, 866), (949, 866), (949, 1472), (54, 1472)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\freelancer\\student ocr\\test.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mwhile\u001b[39;00m(\u001b[39m1\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m, img)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Global variables\n",
    "drawing = False  # True if mouse is pressed\n",
    "ix, iy = -1, -1\n",
    "rectangle = []  # Store rectangle vertices\n",
    "img = None  # Global image variable\n",
    "ratio = 1  # Ratio of original image size to resized image size\n",
    "\n",
    "# Mouse callback function\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, img, rectangle, ratio\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            img_copy = img.copy()\n",
    "            cv2.rectangle(img_copy, (ix, iy), (x, y), (0, 255, 0), 2)\n",
    "            cv2.imshow('image', img_copy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        cv2.rectangle(img, (ix, iy), (x, y), (0, 255, 0), 2)\n",
    "        # Store rectangle vertices\n",
    "        rectangle = [(int(ix*ratio), int(iy*ratio)), (int(x*ratio), int(iy*ratio)), (int(x*ratio), int(y*ratio)), (int(ix*ratio), int(y*ratio))]  \n",
    "        print('Rectangle vertices:', rectangle)\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('Major P/Adobe Scan 20-Sep-2023_4 (1).jpg')\n",
    "\n",
    "# Resize image to fit the window\n",
    "window_width = 800\n",
    "ratio = img.shape[1] / window_width\n",
    "dimensions = (window_width, int(img.shape[0] / ratio))\n",
    "img = cv2.resize(img, dimensions, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.setMouseCallback('image', draw_rectangle)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread('Major P/Adobe Scan 20-Sep-2023_2 (1).jpg')\n",
    "\n",
    "# Define your own polygon\n",
    "pts = np.array([[54, 866], [949, 866], [949, 1472], [54, 1472]], np.int32)\n",
    "\n",
    "# Reshape your points in the form required by polylines\n",
    "pts = pts.reshape((-1, 1, 2))\n",
    "\n",
    "# Creating a blank mask\n",
    "mask = np.zeros_like(img)\n",
    "\n",
    "# Fill the mask polygon with white\n",
    "cv2.fillPoly(mask, [pts], (255, 255, 255))\n",
    "\n",
    "# Bitwise-AND mask and original image to get the ROI\n",
    "roi = cv2.bitwise_and(img, mask)\n",
    "\n",
    "# Crop the ROI to remove the black background\n",
    "x, y, w, h = cv2.boundingRect(pts)  # Get the bounding rectangle of the polygon\n",
    "cropped_roi = roi[y:y+h, x:x+w]\n",
    "\n",
    "# Convert the cropped ROI to grayscale\n",
    "cropped_roi_gray = cv2.cvtColor(cropped_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Sharpen the image\n",
    "sharpened_image = cv2.filter2D(cropped_roi_gray, -1, np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]))\n",
    "\n",
    "# Increase the size by a factor (e.g., 2x)\n",
    "scaling_factor = 2\n",
    "sharpened_image = cv2.resize(sharpened_image, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Save the sharpened and upscaled image as a JPEG image\n",
    "cv2.imwrite('1.jpg', sharpened_image)\n",
    "\n",
    "# Show the sharpened and upscaled image\n",
    "cv2.imshow(\"Sharpened Image\", sharpened_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the grayscale image\n",
    "cropped_roi_gray = cv2.imread('cropped_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Invert the colors (black to white, white to black)\n",
    "inverted_image = 255 - cropped_roi_gray\n",
    "\n",
    "# Save the inverted grayscale image\n",
    "cv2.imwrite('inverted_image.jpg', inverted_image)\n",
    "\n",
    "# Show the inverted grayscale image\n",
    "cv2.imshow(\"Inverted Image\", inverted_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main code start \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def remove_dots(image, dot_size_threshold):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to create a binary image\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on area to remove small dots\n",
    "    filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > dot_size_threshold]\n",
    "\n",
    "    # Create a mask for the filtered contours\n",
    "    mask = np.zeros_like(binary)\n",
    "    cv2.drawContours(mask, filtered_contours, -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Apply the mask to remove the dots from the original image\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    return result\n",
    "\n",
    "def sharpen_image(image, kernel_size=(5, 5), sigma=1.0):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to the grayscale image\n",
    "    blurred = cv2.GaussianBlur(gray, kernel_size, sigma)\n",
    "\n",
    "    # Calculate the sharpened image by subtracting the blurred image from the original grayscale image\n",
    "    sharpened = cv2.addWeighted(gray, 1.5, blurred, -0.5, 0)\n",
    "\n",
    "    # Convert the sharpened image back to BGR color space\n",
    "    sharpened_bgr = cv2.cvtColor(sharpened, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    return sharpened_bgr\n",
    "\n",
    "# Load the image\n",
    "image_path = 'b.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Remove dots\n",
    "\n",
    "# Sharpen the image\n",
    "sharpened_image = sharpen_image(image)\n",
    "\n",
    "# Display the results\n",
    "cv2.imwrite('b.jpg',sharpened_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Major P\\\\Adobe Scan 20-Sep-2023_1 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_1 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_10 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_10 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_11 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_11 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_12 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_12 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_13 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_13 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_14 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_14 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_15 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_15 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_16 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_16 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_17 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_17 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_18 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_18 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_19 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_19 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_2 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_2 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_20 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_20 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_21 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_21 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_22 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_22 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_23 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_23 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_24 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_24 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_3 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_3 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_4 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_4 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_5 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_5 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_6 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_6 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_7 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_7 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_8 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_8 (2).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_9 (1).jpg',\n",
       " '../Major P\\\\Adobe Scan 20-Sep-2023_9 (2).jpg',\n",
       " '../Major P\\\\dataset-1(537158807927885).jpg',\n",
       " '../Major P\\\\dataset-10(537158974251246).jpg',\n",
       " '../Major P\\\\dataset-11(537158989427705).jpg',\n",
       " '../Major P\\\\dataset-12(537159005564730).jpg',\n",
       " '../Major P\\\\dataset-13(537159024155921).jpg',\n",
       " '../Major P\\\\dataset-14(537159039715962).jpg',\n",
       " '../Major P\\\\dataset-15(537159059209171).jpg',\n",
       " '../Major P\\\\dataset-16(537159073762517).jpg',\n",
       " '../Major P\\\\dataset-17(537159091295464).jpg',\n",
       " '../Major P\\\\dataset-18(537159103784986).jpg',\n",
       " '../Major P\\\\dataset-19(537159121211540).jpg',\n",
       " '../Major P\\\\dataset-2(537158831298101).jpg',\n",
       " '../Major P\\\\dataset-20(537159138282715).jpg',\n",
       " '../Major P\\\\dataset-21(537159159624024).jpg',\n",
       " '../Major P\\\\dataset-22(537159174431798).jpg',\n",
       " '../Major P\\\\dataset-23(537159186045722).jpg',\n",
       " '../Major P\\\\dataset-24(537159196523584).jpg',\n",
       " '../Major P\\\\dataset-25(537159210441579).jpg',\n",
       " '../Major P\\\\dataset-26(537159226315723).jpg',\n",
       " '../Major P\\\\dataset-27(537159285876323).jpg',\n",
       " '../Major P\\\\dataset-28(537159304786461).jpg',\n",
       " '../Major P\\\\dataset-29(537159320833261).jpg',\n",
       " '../Major P\\\\dataset-3(537158850556509).jpg',\n",
       " '../Major P\\\\dataset-30(537159333339968).jpg',\n",
       " '../Major P\\\\dataset-31(537159360489020).jpg',\n",
       " '../Major P\\\\dataset-32(537159374636305).jpg',\n",
       " '../Major P\\\\dataset-33(537159397381516).jpg',\n",
       " '../Major P\\\\dataset-34(537159409266780).jpg',\n",
       " '../Major P\\\\dataset-35(537159424779226).jpg',\n",
       " '../Major P\\\\dataset-36(537159437303004).jpg',\n",
       " '../Major P\\\\dataset-37(537159450006478).jpg',\n",
       " '../Major P\\\\dataset-38(537159460696929).jpg',\n",
       " '../Major P\\\\dataset-39(537159475650966).jpg',\n",
       " '../Major P\\\\dataset-4(537158867818823).jpg',\n",
       " '../Major P\\\\dataset-5(537158886647404).jpg',\n",
       " '../Major P\\\\dataset-6(537158901826832).jpg',\n",
       " '../Major P\\\\dataset-7(537158923280730).jpg',\n",
       " '../Major P\\\\dataset-8(537158943966953).jpg',\n",
       " '../Major P\\\\dataset-9(537158958303188).jpg',\n",
       " '../Major P\\\\dataset_-10(677458586596763).jpg',\n",
       " '../Major P\\\\dataset_-11(677458608452471).jpg',\n",
       " '../Major P\\\\dataset_-14(677458659631124).jpg',\n",
       " '../Major P\\\\dataset_-15(677458670496243).jpg',\n",
       " '../Major P\\\\dataset_-17(677458694710307).jpg',\n",
       " '../Major P\\\\dataset_-18(677458706383905).jpg',\n",
       " '../Major P\\\\dataset_-19(677458723911261).jpg',\n",
       " '../Major P\\\\dataset_-21(677458756152612).jpg',\n",
       " '../Major P\\\\dataset_-22(677458773321114).jpg',\n",
       " '../Major P\\\\dataset_-23(677458793672625).jpg',\n",
       " '../Major P\\\\dataset_-24(677458804990806).jpg',\n",
       " '../Major P\\\\dataset_-25(677458822441160).jpg',\n",
       " '../Major P\\\\dataset_-26(677458837502146).jpg',\n",
       " '../Major P\\\\dataset_-27(677458857733516).jpg',\n",
       " '../Major P\\\\dataset_-3(677458427819884).jpg',\n",
       " '../Major P\\\\dataset_-34(677458963951051).jpg',\n",
       " '../Major P\\\\dataset_-4(677458453412519).jpg',\n",
       " '../Major P\\\\dataset_-40(677459051859016).jpg',\n",
       " '../Major P\\\\dataset_-43(677459097490619).jpg',\n",
       " '../Major P\\\\dataset_-45(677459120647395).jpg',\n",
       " '../Major P\\\\dataset_-47(677459147815637).jpg',\n",
       " '../Major P\\\\dataset_-48(677459169016159).jpg',\n",
       " '../Major P\\\\dataset_-49(677459181101435).jpg',\n",
       " '../Major P\\\\dataset_-50(677459193815868).jpg',\n",
       " '../Major P\\\\dataset_-53(677459267013090).jpg',\n",
       " '../Major P\\\\dataset_-7(677458531725187).jpg',\n",
       " '../Major P\\\\dataset_-8(677458548816366).jpg',\n",
       " '../Major P\\\\dataset_-9(677458567951946).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-1(323697843849778).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-10(323698293416317).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-11(323698328245163).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-12(323698395138317).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-13(323698459157970).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-14(323698534970740).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-15(323698571706586).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-16(323698612503470).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-17(323698637673932).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-18(323698675812701).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-19(323698699037662).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-2(323697980954432).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-3(323698018221317).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-4(323698055803548).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-5(323698106345701).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-6(323698160183471).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-7(323698201278971).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-8(323698234021547).jpg',\n",
       " '../Major P\\\\DocScanner 20 Sept 2023 2-24 pm-9(323698262927894).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-1(535468635500501).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-10(535468785977278).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-11(535468810141724).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-12(535468834519199).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-13(535468852971241).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-14(535468868346922).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-15(535468886428711).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-16(535468901007836).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-17(535468922520656).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-18(535468937195647).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-19(535468952337597).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-2(535468665098277).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-20(535468971900754).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-21(535468985197777).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-22(535468998326649).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-23(535469008232740).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-24(535469024344999).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-25(535469036452080).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-26(535469048706319).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-27(535469067420163).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-28(535469081829522).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-29(535469095101075).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-3(535468680197860).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-30(535469113685418).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-31(535469132348900).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-32(535469144799115).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-33(535469158865678).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-34(535469168970627).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-35(535469178994420).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-36(535469191882239).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-37(535469206622236).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-38(535469225393083).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-39(535469234840479).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-4(535468693864107).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-5(535468709043736).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-6(535468726880680).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-7(535468736186412).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-8(535468747383207).jpg',\n",
       " '../Major P\\\\DocScanner 20-Sept-2023 14-24-9(535468765186286).jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_19.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_20.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_21.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_22.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_23.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_24.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_25.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_26.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_27.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_28.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_29.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_30.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_31.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_32.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_33.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_34.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_35.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_36.jpg',\n",
       " '../Major P\\\\Sample_Pic-MP_37.jpg',\n",
       " '../Major P\\\\Set-3_37.jpg',\n",
       " '../Major P\\\\Set-3_38.jpg',\n",
       " '../Major P\\\\Set-3_39.jpg',\n",
       " '../Major P\\\\Set-3_40.jpg',\n",
       " '../Major P\\\\Set-3_41.jpg',\n",
       " '../Major P\\\\Set-3_42.jpg',\n",
       " '../Major P\\\\Set-3_43.jpg',\n",
       " '../Major P\\\\Set-3_44.jpg',\n",
       " '../Major P\\\\Set-3_45.jpg',\n",
       " '../Major P\\\\Set-3_46.jpg',\n",
       " '../Major P\\\\Set-3_47.jpg',\n",
       " '../Major P\\\\Set-3_48.jpg',\n",
       " '../Major P\\\\Set-3_49.jpg',\n",
       " '../Major P\\\\Set-3_50.jpg',\n",
       " '../Major P\\\\Set-3_51.jpg',\n",
       " '../Major P\\\\Set-3_52.jpg',\n",
       " '../Major P\\\\Set-3_53.jpg',\n",
       " '../Major P\\\\Set-3_54.jpg',\n",
       " '../Major P\\\\Set-3_55.jpg',\n",
       " '../Major P\\\\Set-3_56.jpg',\n",
       " '../Major P\\\\Set-3_57.jpg',\n",
       " '../Major P\\\\Set-3_58.jpg',\n",
       " '../Major P\\\\Set-3_59.jpg',\n",
       " '../Major P\\\\Set-3_60.jpg',\n",
       " '../Major P\\\\set4dataset-43(410409722956872).jpg',\n",
       " '../Major P\\\\set4dataset-44(410409784288449).jpg',\n",
       " '../Major P\\\\set4dataset-45(410409864422795).jpg',\n",
       " '../Major P\\\\set4dataset-46(410409939633757).jpg',\n",
       " '../Major P\\\\set4dataset-55(410410652121333).jpg',\n",
       " '../Major P\\\\set4dataset-56(410410765834910).jpg',\n",
       " '../Major P\\\\set4dataset-57(410410846968025).jpg',\n",
       " '../Major P\\\\set4dataset-58(410410915427948).jpg',\n",
       " '../Major P\\\\set4dataset-59(410410991896794).jpg',\n",
       " '../Major P\\\\set4dataset-60(410411046894179).jpg',\n",
       " '../Major P\\\\set4dataset-61(410411088808294).jpg',\n",
       " '../Major P\\\\set4dataset-62(410411132780525).jpg']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1         3    9             17       NaN\n",
      "2    2             10             18       NaN\n",
      "3    3       2-5   11             19       NaN\n",
      "4    4             12        20            NaN\n",
      "5    5         Ś   13        21            NaN\n",
      "6   60             14        22            NaN\n",
      "7    7             15        23            NaN\n",
      "8    8             16        24            NaN\n",
      "     0         1    2         3         4      5\n",
      "0  No.  Obtained  No.  Obtained  Obtained  Marks\n",
      "1    1         3    9                  17    NaN\n",
      "2    2         2   10                  18    NaN\n",
      "3    3       2-5   11                  19    NaN\n",
      "4    5             12        20              NaN\n",
      "5    5             13        21              NaN\n",
      "6    6             14        22              NaN\n",
      "7    7             15        23              NaN\n",
      "8    8             16        24              NaN\n",
      "     0         1         2    3   4         5\n",
      "0  No.  Obtained  Obtained  No.      Obtained\n",
      "1    1                   9       17       NaN\n",
      "2    2        10             18           NaN\n",
      "3    с                  11   19           NaN\n",
      "4    4                  12   20           NaN\n",
      "5    5                  13   21           NaN\n",
      "6    0        14             22           NaN\n",
      "7    7       2.5        15   23           NaN\n",
      "8    0        16             24           NaN\n",
      "     0         1    2    3         4      5\n",
      "0  No.  Obtained  No.  No.  Obtained  Marks\n",
      "1    1              9   17              NaN\n",
      "2    2        10        18              NaN\n",
      "3    O        11        19              NaN\n",
      "4    4        12        20              NaN\n",
      "5    1        13        21              NaN\n",
      "6    6        14        22              NaN\n",
      "7    7        15        23              NaN\n",
      "8    8        16        24              NaN\n",
      "       0         1    2         3    4         5\n",
      "0    No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1      3              9             17       NaN\n",
      "2      2             10             18       NaN\n",
      "3      3             11             19       NaN\n",
      "4      4             12             20       NaN\n",
      "5      1             13             21       NaN\n",
      "6      6             14             22       NaN\n",
      "7  INTER             15             23       NaN\n",
      "8      8             16             24       NaN\n",
      "     0         1    2    3      4         5\n",
      "0  No.  Obtained  No.  No.  Marks  Obtained\n",
      "1    3              9   17              NaN\n",
      "2    2             10          18       NaN\n",
      "3    S             11          19       NaN\n",
      "4    4             12          20       NaN\n",
      "5    1             13          21       NaN\n",
      "6    6             14          22       NaN\n",
      "7    7             15          23       NaN\n",
      "8    8             16          24       NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    O              9             17       NaN\n",
      "2    2             10             18       NaN\n",
      "3    3             11             19       NaN\n",
      "4    5             12             20       NaN\n",
      "5    5             13             21       NaN\n",
      "6    6         O   14             22       NaN\n",
      "7    7             15             23       NaN\n",
      "8    8             16             24       NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1              9             17       NaN\n",
      "2    1             10             18       NaN\n",
      "3    3             11             19       NaN\n",
      "4    5             12        20            NaN\n",
      "5    5             13        21            NaN\n",
      "6    6             14             22       NaN\n",
      "7    7             15        23            NaN\n",
      "8    8             16        24            NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1        01    9             17       NaN\n",
      "2    2         C   10             18       NaN\n",
      "3    3         1   11             19       NaN\n",
      "4    4         O   12             20       NaN\n",
      "5    5       0.5   13             21       NaN\n",
      "6    6             14             22       NaN\n",
      "7  1.5             15             23       NaN\n",
      "8    8         2   16             24       NaN\n",
      "     0         1    2    3      4         5\n",
      "0  No.  Obtained  No.  No.  Marks  Obtained\n",
      "1    1        01    9          17       NaN\n",
      "2    2             10          18       NaN\n",
      "3    3             11          19       NaN\n",
      "4    4         Ⓒ   12          20       NaN\n",
      "5    5             13          21       NaN\n",
      "6    6             14          22       NaN\n",
      "7    7             15          23       NaN\n",
      "8    8         2   16          24       NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Question  No.  Obtained  No.  Obtained\n",
      "1    1              9        17            NaN\n",
      "2    0             10             18       NaN\n",
      "3    J             11             19       NaN\n",
      "4    0             12        20            NaN\n",
      "5    5             13        21            NaN\n",
      "6    6             14        22            NaN\n",
      "7    7             15             23       NaN\n",
      "8    8             16             24       NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1              9             17       NaN\n",
      "2    2             10             18       NaN\n",
      "3    3             11             19       NaN\n",
      "4    4             12        20            NaN\n",
      "5   СЛ             13             21       NaN\n",
      "6    6             14        22            NaN\n",
      "7    7             15             23       NaN\n",
      "8    8             16             24       NaN\n",
      "      0    1         2    3      4         5\n",
      "0   No.  No.  Obtained  No.  Marks  Obtained\n",
      "1     5              9   17              NaN\n",
      "2     3             10   18              NaN\n",
      "3     3             11   19              NaN\n",
      "4     4             12   20              NaN\n",
      "5     5             13   21              NaN\n",
      "6     6             14   22              NaN\n",
      "7  4145             15   23              NaN\n",
      "8     8    5        16   24              NaN\n",
      "     0         1    2    3      4         5\n",
      "0  No.  Obtained  No.  No.  Marks  Obtained\n",
      "1    5         9               17       NaN\n",
      "2    3             10          18       NaN\n",
      "3    3             11   19              NaN\n",
      "4   40        12        20              NaN\n",
      "5    5             13   21              NaN\n",
      "6    6             14          22       NaN\n",
      "7   44             15   23              NaN\n",
      "8    8             16   24              NaN\n",
      "          0    1         2    3      4         5\n",
      "0  Obtained  No.  Obtained  No.  Marks  Obtained\n",
      "1         1    9             17              NaN\n",
      "2         2   10             18              NaN\n",
      "3         3   11             19              NaN\n",
      "4         4   12             20              NaN\n",
      "5         5   13             21              NaN\n",
      "6         6   14             22              NaN\n",
      "7         7             15   23              NaN\n",
      "8         8             16   24              NaN\n",
      "     0    1         2    3         4      5\n",
      "0  No.  No.  Obtained  No.  Obtained  Marks\n",
      "1         9                             NaN\n",
      "2    2   10             17              NaN\n",
      "3    3   11             19              NaN\n",
      "4    4   12                             NaN\n",
      "5   сл   13             20              NaN\n",
      "6    6   14             22              NaN\n",
      "7    7   15             23              NaN\n",
      "8    8             16   24              NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1         2    9             17       NaN\n",
      "2    2         3   10             18       NaN\n",
      "3    5             11        19            NaN\n",
      "4    0             12        20            NaN\n",
      "5    5        It   13        21            NaN\n",
      "6    6             14        22            NaN\n",
      "7    7       0.5   15        23            NaN\n",
      "8   CO             16        24            NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1         2    9             17       NaN\n",
      "2    2         3   10        18            NaN\n",
      "3    5             11        19            NaN\n",
      "4    0             12        20            NaN\n",
      "5    5       IFT   13        21            NaN\n",
      "6    6             14        22            NaN\n",
      "7    7         Ś   15        23            NaN\n",
      "8    8        16             24            NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1         0    9             17       NaN\n",
      "2    2             10             18       NaN\n",
      "3    3             11             19       NaN\n",
      "4                  12             20       NaN\n",
      "5    5         0   13             21       NaN\n",
      "6    6             14             22       NaN\n",
      "7    7             15             23       NaN\n",
      "8    8             16             24       NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1         0    9             17       NaN\n",
      "2    2             10             18       NaN\n",
      "3    3             11             19       NaN\n",
      "4    4             12             20       NaN\n",
      "5    5             13             21       NaN\n",
      "6    6       010   14             22       NaN\n",
      "7    7             15             23       NaN\n",
      "8    8             16             24       NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1              9             17       NaN\n",
      "2    2         2   10             18       NaN\n",
      "3    3         2   11             19       NaN\n",
      "4    4             12             20       NaN\n",
      "5    5             13             21       NaN\n",
      "6    6             14             22       NaN\n",
      "7    7             15        23            NaN\n",
      "8    8         5   16             24       NaN\n",
      "     0         1    2         3         4      5\n",
      "0  No.  Obtained  No.  Obtained  Obtained  Marks\n",
      "1    1              9                  17    NaN\n",
      "2    2         2   10                  18    NaN\n",
      "3    3             11        19              NaN\n",
      "4    4             12        20              NaN\n",
      "5    5             13        21              NaN\n",
      "6    6             14        22              NaN\n",
      "7    7             15        23              NaN\n",
      "8    8             16        24              NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1              9             17       NaN\n",
      "2    2             10             18       NaN\n",
      "3    3             11             19       NaN\n",
      "4    2             12        20            NaN\n",
      "5    5             13             21       NaN\n",
      "6    6             14        22            NaN\n",
      "7   3.         S   15        23            NaN\n",
      "8    8             16             24       NaN\n",
      "     0         1    2         3         4      5\n",
      "0  No.  Obtained  No.  Obtained  Obtained  Marks\n",
      "1    4              9                  17    NaN\n",
      "2    2             10                  18    NaN\n",
      "3    3             11                  19    NaN\n",
      "4    2             12                  20    NaN\n",
      "5    5             13                  21    NaN\n",
      "6    O             14        22              NaN\n",
      "7   3.        S.   15                  23    NaN\n",
      "8    Y             16                  24    NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    3              9             17       NaN\n",
      "2    2         0   10             18       NaN\n",
      "3   ني      21-5   11             19       NaN\n",
      "4    4             12             20       NaN\n",
      "5    5             13             21       NaN\n",
      "6    6         0   14             22       NaN\n",
      "7    7             15             23       NaN\n",
      "8    8         0   16             24       NaN\n",
      "     0         1    2         3    4         5\n",
      "0  No.  Obtained  No.  Obtained  No.  Obtained\n",
      "1    1              9             17       NaN\n",
      "2    2             10             18       NaN\n",
      "3    3      01-5   11             19       NaN\n",
      "4    4             12             20       NaN\n",
      "5    5         8   13             21       NaN\n",
      "6    6         0   14             22       NaN\n",
      "7    7         0   15        23            NaN\n",
      "8    8             16             24       NaN\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\freelancer\\student ocr\\test.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W6sZmlsZQ%3D%3D?line=224'>225</a>\u001b[0m request \u001b[39m=\u001b[39m types\u001b[39m.\u001b[39mAnnotateImageRequest(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W6sZmlsZQ%3D%3D?line=225'>226</a>\u001b[0m     image\u001b[39m=\u001b[39mimage,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W6sZmlsZQ%3D%3D?line=226'>227</a>\u001b[0m     features\u001b[39m=\u001b[39m[types\u001b[39m.\u001b[39mFeature(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTEXT_DETECTION\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W6sZmlsZQ%3D%3D?line=227'>228</a>\u001b[0m )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W6sZmlsZQ%3D%3D?line=229'>230</a>\u001b[0m \u001b[39m# Send the request and get the response\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W6sZmlsZQ%3D%3D?line=230'>231</a>\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mannotate_image(request)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W6sZmlsZQ%3D%3D?line=231'>232</a>\u001b[0m text_annotations \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mtext_annotations\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/freelancer/student%20ocr/test.ipynb#W6sZmlsZQ%3D%3D?line=232'>233</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\vision_helpers\\__init__.py:76\u001b[0m, in \u001b[0;36mVisionHelpers.annotate_image\u001b[1;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(request\u001b[39m.\u001b[39mfeatures) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     75\u001b[0m     request\u001b[39m.\u001b[39mfeatures \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_all_features()\n\u001b[1;32m---> 76\u001b[0m r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_annotate_images(\n\u001b[0;32m     77\u001b[0m     requests\u001b[39m=\u001b[39;49m[request], retry\u001b[39m=\u001b[39;49mretry, timeout\u001b[39m=\u001b[39;49mtimeout, metadata\u001b[39m=\u001b[39;49mmetadata\n\u001b[0;32m     78\u001b[0m )\n\u001b[0;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mresponses[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\vision_v1\\services\\image_annotator\\client.py:564\u001b[0m, in \u001b[0;36mImageAnnotatorClient.batch_annotate_images\u001b[1;34m(self, request, requests, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    561\u001b[0m rpc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39m_wrapped_methods[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39mbatch_annotate_images]\n\u001b[0;32m    563\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 564\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[0;32m    565\u001b[0m     request,\n\u001b[0;32m    566\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[0;32m    567\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    568\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m    569\u001b[0m )\n\u001b[0;32m    571\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\api_core\\grpc_helpers.py:75\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(callable_)\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_remapped_callable\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     74\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m         \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m     \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     77\u001b[0m         \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\grpc\\_channel.py:1158\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1148\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     compression: Optional[grpc\u001b[39m.\u001b[39mCompression] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1154\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m   1155\u001b[0m     (\n\u001b[0;32m   1156\u001b[0m         state,\n\u001b[0;32m   1157\u001b[0m         call,\n\u001b[1;32m-> 1158\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_blocking(\n\u001b[0;32m   1159\u001b[0m         request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1160\u001b[0m     )\n\u001b[0;32m   1161\u001b[0m     \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\grpc\\_channel.py:1142\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1126\u001b[0m state\u001b[39m.\u001b[39mmethod \u001b[39m=\u001b[39m _common\u001b[39m.\u001b[39mdecode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_method)\n\u001b[0;32m   1127\u001b[0m call \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_channel\u001b[39m.\u001b[39msegregated_call(\n\u001b[0;32m   1128\u001b[0m     cygrpc\u001b[39m.\u001b[39mPropagationConstants\u001b[39m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[0;32m   1129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context,\n\u001b[0;32m   1141\u001b[0m )\n\u001b[1;32m-> 1142\u001b[0m event \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49mnext_event()\n\u001b[0;32m   1143\u001b[0m _handle_event(event, state, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_deserializer)\n\u001b[0;32m   1144\u001b[0m \u001b[39mreturn\u001b[39;00m state, call\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/channel.pyx.pxi:366\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/channel.pyx.pxi:187\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/channel.pyx.pxi:181\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/completion_queue.pyx.pxi:62\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/completion_queue.pyx.pxi:58\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._interpret_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/tag.pyx.pxi:71\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._BatchOperationTag.event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/operation.pyx.pxi:138\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.ReceiveInitialMetadataOperation.un_c\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/metadata.pyx.pxi:69\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._metadata\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/metadata.pyx.pxi:70\u001b[0m, in \u001b[0;36mgenexpr\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\python\\grpcio\\grpc\\_cython\\_cygrpc/metadata.pyx.pxi:64\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._metadatum\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(_cls, key, value)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "net = cv2.dnn.readNetFromONNX(\"best.onnx\")\n",
    "file = open(\"coco.txt\", \"r\")\n",
    "classes = file.read().split('\\n')\n",
    "import os\n",
    "\n",
    "# Directory path where your images are located\n",
    "folder_path = \"../Major P\"\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# Filter the list to only include image files (e.g., .jpg, .png, .jpeg)\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.gif']  # Add more extensions if needed\n",
    "image_paths = [os.path.join(folder_path, file) for file in file_list if any(file.lower().endswith(ext) for ext in image_extensions)]\n",
    "  # Add the paths of the images you want to process\n",
    "\n",
    "for image_path in image_paths:\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    img_height, img_width = img.shape[:2]  # Get the height and width of the image\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, scalefactor=1/255, size=(640, 640), mean=[0, 0, 0], swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()[0]\n",
    "\n",
    "    # cx, cy, w, h, confidence, 80 class_scores\n",
    "    # class_ids, confidences, boxes\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    rows = detections.shape[0]\n",
    "\n",
    "    x_scale = img_width / 640\n",
    "    y_scale = img_height / 640\n",
    "\n",
    "    for i in range(rows):\n",
    "        row = detections[i]\n",
    "        confidence = row[4]\n",
    "        if confidence > 0.5:\n",
    "            class_scores = row[5:]\n",
    "            ind = np.argmax(class_scores)\n",
    "            if class_scores[ind] > 0.5:\n",
    "                class_ids.append(ind)\n",
    "                confidences.append(confidence)\n",
    "                cx, cy, w, h = row[:4]\n",
    "                x1 = int((cx - w / 2) * x_scale)\n",
    "                y1 = int((cy - h / 2) * y_scale)\n",
    "                width = int(w * x_scale)\n",
    "                height = int(h * y_scale)\n",
    "                box = np.array([x1, y1, width, height])\n",
    "                boxes.append(box)\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.5)\n",
    "\n",
    "    for i in indices:\n",
    "        x1, y1, w, h = boxes[i]\n",
    "        label = classes[class_ids[i]]\n",
    "        conf = confidences[i]\n",
    "        text = label + \" {:.2f}\".format(conf)\n",
    "\n",
    "        # Crop the detection region\n",
    "        crop_img = img[y1:y1+h, x1:x1+w]\n",
    "\n",
    "        # Save cropped image with the respective class name\n",
    "        save_path = f\"{label}.jpg\"\n",
    "        cv2.imwrite(save_path, crop_img)\n",
    "\n",
    "        cv2.rectangle(img, (x1, y1), (x1 + w, y1 + h), (255, 0, 0), 2)\n",
    "        cv2.putText(img, text, (x1, y1 - 2), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255, 0, 255), 2)\n",
    "\n",
    "    cv2.imwrite('my.jpg',img)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    # Load an image\n",
    "    image = cv2.imread('b.jpg')\n",
    "\n",
    "    # Create a sharpening kernel\n",
    "    sharpening_kernel = np.array([[-1, -1, -1],\n",
    "                                [-1,  9, -1],\n",
    "                                [-1, -1, -1]])\n",
    "\n",
    "    # Apply the convolution to sharpen the image\n",
    "    sharpened_image = cv2.filter2D(image, -1, sharpening_kernel)\n",
    "\n",
    "    # Display the original and sharpened images\n",
    "\n",
    "    cv2.imwrite('b.jpg', sharpened_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    import io\n",
    "    import os\n",
    "\n",
    "    from google.cloud import vision\n",
    "    from google.cloud.vision_v1 import types\n",
    "\n",
    "    # Set your environment variable for your GCP credentials\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'circular-genius-402810-13afeaaa2b14.json'\n",
    "\n",
    "    # Initialize the Vision API client\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # Load the image\n",
    "    with io.open('b.jpg', 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    # Create the text detection request\n",
    "    request = types.AnnotateImageRequest(\n",
    "        image=image,\n",
    "        features=[types.Feature(type='TEXT_DETECTION')]\n",
    "    )\n",
    "\n",
    "    # Send the request and get the response\n",
    "    response = client.annotate_image(request)\n",
    "\n",
    "\n",
    "    import json\n",
    "    from google.protobuf.json_format import MessageToDict\n",
    "    response_dict = MessageToDict(response._pb)\n",
    "\n",
    "    # Access the textAnnotations\n",
    "    text_annotations = response_dict.get('textAnnotations', [])\n",
    "\n",
    "    # Function to calculate the center point of a bounding box\n",
    "    def calculate_center(vertices):\n",
    "        x_coordinates = [vertex['x'] for vertex in vertices]\n",
    "        y_coordinates = [vertex['y'] for vertex in vertices]\n",
    "        center_x = sum(x_coordinates) / len(vertices)\n",
    "        center_y = sum(y_coordinates) / len(vertices)\n",
    "        return center_x, center_y\n",
    "\n",
    "    # Calculate center points for all bounding boxes along with descriptions\n",
    "    center_points_with_descriptions = []\n",
    "    for annotation in text_annotations[1:]:\n",
    "        description = annotation.get('description', 'N/A')  # Use 'N/A' if description is not present\n",
    "        vertices = annotation['boundingPoly']['vertices']\n",
    "        center_x, center_y = calculate_center(vertices)\n",
    "        center_points_with_descriptions.append({'description': description, 'x': center_x, 'y': center_y})\n",
    "\n",
    "\n",
    "\n",
    "    data = center_points_with_descriptions\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Define the target number of rows in column 0\n",
    "    target_rows_in_col0 = 5\n",
    "    y_threshold = 40  # Start with the initial threshold\n",
    "\n",
    "    while True:\n",
    "        # Calculate the bins for x based on the number of columns\n",
    "        x_bins = np.linspace(df['x'].min(), df['x'].max(), target_rows_in_col0 + 1)\n",
    "\n",
    "        # Assign each point to a cell in the table\n",
    "        df['column'] = np.digitize(df['x'], x_bins) - 1\n",
    "\n",
    "        # Create 'y_bins' using the updated 'y_threshold'\n",
    "        y_bins = np.arange(df['y'].min(), df['y'].max() + y_threshold, y_threshold)\n",
    "\n",
    "        # Assign each point to a row in the table\n",
    "        df['row'] = np.digitize(df['y'], y_bins) - 1\n",
    "\n",
    "        # Calculate the number of unique rows in column 0\n",
    "        num_unique_rows_in_col0 = len(df[df['column'] == 0]['row'].unique())\n",
    "    \n",
    "        \n",
    "        # Calculate the number of rows dynamically based on the 'row' column\n",
    "        num_rows = df['row'].max() + 1\n",
    "\n",
    "        # Create a table with the specified number of rows and columns\n",
    "        table = pd.DataFrame('', index=np.arange(num_rows), columns=np.arange(target_rows_in_col0))\n",
    "\n",
    "        # Fill the table with the descriptions from the data\n",
    "        for i, row in df.iterrows():\n",
    "            table.at[row['row'], row['column']] = row['description']\n",
    "\n",
    "        # If the number of unique rows in column 0 matches the target, exit the loop\n",
    "        if table.shape[0] == 9:\n",
    "            break\n",
    "\n",
    "        # Increase the y_threshold for the next iteration\n",
    "        y_threshold += 1  # You can adjust the step as needed\n",
    "\n",
    "    # Calculate the number of rows dynamically based on the 'row' column\n",
    "    num_rows = df['row'].max() + 1\n",
    "\n",
    "    # Create a table with the specified number of rows and columns\n",
    "    table = pd.DataFrame('', index=np.arange(num_rows), columns=np.arange(target_rows_in_col0))\n",
    "\n",
    "    # Fill the table with the descriptions from the data\n",
    "    for i, row in df.iterrows():\n",
    "        table.at[row['row'], row['column']] = row['description']\n",
    "\n",
    "    # Print the resulting table\n",
    "    print(table)\n",
    "    table.columns = table.columns.astype(str)\n",
    "    table = table.drop(table.index[0])\n",
    "    df=table\n",
    "    new_df = df.replace('', np.nan)\n",
    "\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'circular-genius-402810-13afeaaa2b14.json'\n",
    "\n",
    "    # Initialize the Vision API client\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # Load the image\n",
    "    with io.open('a.jpg', 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    # Create the text detection request\n",
    "    request = types.AnnotateImageRequest(\n",
    "        image=image,\n",
    "        features=[types.Feature(type='TEXT_DETECTION')]\n",
    "    )\n",
    "\n",
    "    # Send the request and get the response\n",
    "    response = client.annotate_image(request)\n",
    "    text_annotations = response.text_annotations\n",
    "    import re\n",
    "    # Get the first text annotation (which contains the entire text)\n",
    "\n",
    "    full_text = text_annotations[0].description\n",
    "\n",
    "    full_text = 'Enrolment No.:___220479'\n",
    "    digits = re.sub(r'\\D', '', full_text)\n",
    "\n",
    "\n",
    "    # Load the existing DataFrame from the CSV file\n",
    "    main_data = pd.read_csv('v.csv')\n",
    "\n",
    "    # Your list containing question numbers and marks\n",
    "    data_list = [digits] + list(new_df['1']) + list(new_df['3']) + list(new_df['5'])\n",
    "\n",
    "    # Create a new row as a DataFrame with the same column names as the main_data\n",
    "    new_row = pd.DataFrame([data_list], columns=main_data.columns)\n",
    "\n",
    "    # Concatenate the new row to the existing DataFrame\n",
    "    existing_df = pd.concat([main_data, new_row], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame to the CSV file without creating new columns\n",
    "    existing_df.to_csv('v.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>o</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3-5</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3   4    5\n",
       "1  1    o   9 NaN  17  NaN\n",
       "2  2    2  10 NaN  18  NaN\n",
       "3  4  NaN  11 NaN  19  NaN\n",
       "4  5  NaN  12 NaN  20  NaN\n",
       "5  2    .  13 NaN  21  NaN\n",
       "6  6  NaN  14 NaN  22  NaN\n",
       "7  1  3-5  15 NaN  23  NaN\n",
       "8  8    5  16 NaN  24  NaN"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.columns = table.columns.astype(str)\n",
    "table = table.drop(table.index[0])\n",
    "df=table\n",
    "new_df = df.replace('', np.nan)\n",
    "# Load the existing DataFrame from the CSV file\n",
    "main_data = pd.read_csv('v.csv')\n",
    "\n",
    "# Your list containing question numbers and marks\n",
    "data_list = ['098'] + list(new_df['1']) + list(new_df['3']) + list(new_df['5'])\n",
    "\n",
    "# Create a new row as a DataFrame with the same column names as the main_data\n",
    "new_row = pd.DataFrame([data_list], columns=main_data.columns)\n",
    "\n",
    "# Concatenate the new row to the existing DataFrame\n",
    "existing_df = pd.concat([main_data, new_row], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame to the CSV file without creating new columns\n",
    "existing_df.to_csv('v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the existing DataFrame from the CSV file\n",
    "main_data = pd.read_csv('v.csv')\n",
    "\n",
    "# Your list containing question numbers and marks\n",
    "data_list = ['098'] + list(new_df['1']) + list(new_df['3']) + list(new_df['5'])\n",
    "\n",
    "# Create a new row as a DataFrame with the same column names as the main_data\n",
    "new_row = pd.DataFrame([data_list], columns=main_data.columns)\n",
    "\n",
    "# Concatenate the new row to the existing DataFrame\n",
    "existing_df = pd.concat([main_data, new_row], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame to the CSV file without creating new columns\n",
    "existing_df.to_csv('v.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['o', '3-5'], 2: ['2', '.'], 4: [nan], 5: [nan], 6: [nan], 8: ['5'], 9: [nan], 10: [nan], 11: [nan], 12: [nan], 13: [nan], 14: [nan], 15: [nan], 16: [nan], 17: [nan], 18: [nan], 19: [nan], 20: [nan], 21: [nan], 22: [nan], 23: [nan], 24: [nan]}\n"
     ]
    }
   ],
   "source": [
    "v = {}\n",
    "\n",
    "# Iterate through the DataFrame columns to extract question numbers and marks\n",
    "for col in new_df.columns:\n",
    "    try:\n",
    "        col_int = int(col)  # Convert the column name to an integer\n",
    "    except ValueError:\n",
    "        continue  # Skip columns that cannot be converted to an integer\n",
    "    if col_int % 2 == 0:\n",
    "        question = new_df[col].dropna().astype(int).values\n",
    "    else:\n",
    "        marks = new_df[col].values\n",
    "        for q, mark in zip(question, marks):\n",
    "            if q not in v:\n",
    "                v[q] = []\n",
    "            v[q].append(mark if mark is not None else new_df['0'][col_int])\n",
    "\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obtained</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Obtained</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Obtained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variable         1         3         5\n",
       "0         Obtained       NaN       NaN\n",
       "1                o       NaN       NaN\n",
       "2                2       NaN       NaN\n",
       "3                4       NaN       NaN\n",
       "4                5       NaN       NaN\n",
       "5                .       NaN       NaN\n",
       "6                        NaN       NaN\n",
       "7              3-5       NaN       NaN\n",
       "8                5       NaN       NaN\n",
       "9              NaN  Obtained       NaN\n",
       "10             NaN                 NaN\n",
       "11             NaN                 NaN\n",
       "12             NaN                 NaN\n",
       "13             NaN                 NaN\n",
       "14             NaN                 NaN\n",
       "15             NaN                 NaN\n",
       "16             NaN                 NaN\n",
       "17             NaN                 NaN\n",
       "18             NaN       NaN  Obtained\n",
       "19             NaN       NaN          \n",
       "20             NaN       NaN          \n",
       "21             NaN       NaN          \n",
       "22             NaN       NaN          \n",
       "23             NaN       NaN          \n",
       "24             NaN       NaN          \n",
       "25             NaN       NaN          \n",
       "26             NaN       NaN          "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "table.drop('1')\n",
    "\n",
    "# Assuming your DataFrame is named 'table'\n",
    "melted_df = pd.melt(table, id_vars=['0', '2', '4'], value_vars=['1', '3', '5'])\n",
    "new_df = melted_df.pivot(columns='variable', values='value')\n",
    "\n",
    "(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "\n",
    "# Set your environment variable for your GCP credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'circular-genius-402810-13afeaaa2b14.json'\n",
    "\n",
    "# Initialize the Vision API client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# Load the image\n",
    "with io.open('a.jpg', 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = types.Image(content=content)\n",
    "\n",
    "# Create the text detection request\n",
    "request = types.AnnotateImageRequest(\n",
    "    image=image,\n",
    "    features=[types.Feature(type='TEXT_DETECTION')]\n",
    ")\n",
    "\n",
    "# Send the request and get the response\n",
    "response = client.annotate_image(request)\n",
    "text_annotations = response.text_annotations\n",
    "import re\n",
    "# Get the first text annotation (which contains the entire text)\n",
    "\n",
    "full_text = text_annotations[0].description\n",
    "\n",
    "full_text = 'Enrolment No.:___220479'\n",
    "digits = re.sub(r'\\D', '', full_text)\n",
    "\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'220479'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Question Marks Question Diarks Question Marks\n",
      "No. Obtained\n",
      "No.\n",
      "Hobtained\n",
      "No. Obtained\n",
      "4\n",
      "19\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "11\n",
      "on\n",
      "5\n",
      "00\n",
      "16\n",
      "21st\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "Text: Question\n",
      "Text: Marks\n",
      "Text: Question\n",
      "Text: Diarks\n",
      "Text: Question\n",
      "Text: Marks\n",
      "Text: No.\n",
      "Text: Obtained\n",
      "Text: No.\n",
      "Text: Hobtained\n",
      "Text: No.\n",
      "Text: Obtained\n",
      "Text: 4\n",
      "Text: 19\n",
      "Text: 10\n",
      "Text: 11\n",
      "Text: 12\n",
      "Text: 13\n",
      "Text: 14\n",
      "Text: 11\n",
      "Text: on\n",
      "Text: 5\n",
      "Text: 00\n",
      "Text: 16\n",
      "Text: 21st\n",
      "Text: 18\n",
      "Text: 19\n",
      "Text: 20\n",
      "Text: 21\n",
      "Text: 22\n",
      "Text: 23\n",
      "Text: 24\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread('bc.jpg')\n",
    "\n",
    "# Create a sharpening kernel\n",
    "sharpening_kernel = np.array([[-1, -1, -1],\n",
    "                              [-1,  9, -1],\n",
    "                              [-1, -1, -1]])\n",
    "\n",
    "# Apply the convolution to sharpen the image\n",
    "sharpened_image = cv2.filter2D(image, -1, sharpening_kernel)\n",
    "\n",
    "# Display the original and sharpened images\n",
    "\n",
    "cv2.imwrite('bc.jpg', sharpened_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import io\n",
    "import os\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "\n",
    "# Set your environment variable for your GCP credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'circular-genius-402810-13afeaaa2b14.json'\n",
    "\n",
    "# Initialize the Vision API client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# Load the image\n",
    "with io.open('bc.jpg', 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = types.Image(content=content)\n",
    "\n",
    "# Create the text detection request\n",
    "request = types.AnnotateImageRequest(\n",
    "    image=image,\n",
    "    features=[types.Feature(type='TEXT_DETECTION')]\n",
    ")\n",
    "\n",
    "# Send the request and get the response\n",
    "response = client.annotate_image(request)\n",
    "g=[]\n",
    "for text_annotation in response.text_annotations:\n",
    "    print('Text:', text_annotation.description)\n",
    "    g.append(text_annotation.description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"description\": \"Question\",\n",
      "    \"x\": 77.0,\n",
      "    \"y\": 42.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Marks\",\n",
      "    \"x\": 230.5,\n",
      "    \"y\": 46.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Question\",\n",
      "    \"x\": 384.0,\n",
      "    \"y\": 46.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Diarks\",\n",
      "    \"x\": 534.0,\n",
      "    \"y\": 46.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Question\",\n",
      "    \"x\": 686.5,\n",
      "    \"y\": 46.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Marks\",\n",
      "    \"x\": 836.0,\n",
      "    \"y\": 46.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"No.\",\n",
      "    \"x\": 76.0,\n",
      "    \"y\": 81.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Obtained\",\n",
      "    \"x\": 232.0,\n",
      "    \"y\": 83.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"No.\",\n",
      "    \"x\": 384.0,\n",
      "    \"y\": 86.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Hobtained\",\n",
      "    \"x\": 528.5,\n",
      "    \"y\": 85.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"No.\",\n",
      "    \"x\": 687.0,\n",
      "    \"y\": 87.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"Obtained\",\n",
      "    \"x\": 839.5,\n",
      "    \"y\": 87.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"4\",\n",
      "    \"x\": 234.0,\n",
      "    \"y\": 144.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"19\",\n",
      "    \"x\": 380.0,\n",
      "    \"y\": 153.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"10\",\n",
      "    \"x\": 383.0,\n",
      "    \"y\": 214.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"11\",\n",
      "    \"x\": 382.5,\n",
      "    \"y\": 273.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"12\",\n",
      "    \"x\": 383.0,\n",
      "    \"y\": 333.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"13\",\n",
      "    \"x\": 380.5,\n",
      "    \"y\": 395.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"14\",\n",
      "    \"x\": 379.5,\n",
      "    \"y\": 455.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"11\",\n",
      "    \"x\": 75.5,\n",
      "    \"y\": 150.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"on\",\n",
      "    \"x\": 73.5,\n",
      "    \"y\": 271.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"5\",\n",
      "    \"x\": 73.0,\n",
      "    \"y\": 393.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"00\",\n",
      "    \"x\": 67.5,\n",
      "    \"y\": 574.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"16\",\n",
      "    \"x\": 379.0,\n",
      "    \"y\": 578.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"21st\",\n",
      "    \"x\": 427.0,\n",
      "    \"y\": 201.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"18\",\n",
      "    \"x\": 686.0,\n",
      "    \"y\": 216.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"19\",\n",
      "    \"x\": 685.5,\n",
      "    \"y\": 275.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"20\",\n",
      "    \"x\": 684.5,\n",
      "    \"y\": 337.0\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"21\",\n",
      "    \"x\": 683.5,\n",
      "    \"y\": 397.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"22\",\n",
      "    \"x\": 683.5,\n",
      "    \"y\": 458.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"23\",\n",
      "    \"x\": 683.5,\n",
      "    \"y\": 517.5\n",
      "  },\n",
      "  {\n",
      "    \"description\": \"24\",\n",
      "    \"x\": 682.5,\n",
      "    \"y\": 580.0\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "response_dict = MessageToDict(response._pb)\n",
    "\n",
    "# Access the textAnnotations\n",
    "text_annotations = response_dict.get('textAnnotations', [])\n",
    "\n",
    "# Function to calculate the center point of a bounding box\n",
    "def calculate_center(vertices):\n",
    "    x_coordinates = [vertex['x'] for vertex in vertices]\n",
    "    y_coordinates = [vertex['y'] for vertex in vertices]\n",
    "    center_x = sum(x_coordinates) / len(vertices)\n",
    "    center_y = sum(y_coordinates) / len(vertices)\n",
    "    return center_x, center_y\n",
    "\n",
    "# Calculate center points for all bounding boxes along with descriptions\n",
    "center_points_with_descriptions = []\n",
    "for annotation in text_annotations[1:]:\n",
    "    description = annotation.get('description', 'N/A')  # Use 'N/A' if description is not present\n",
    "    vertices = annotation['boundingPoly']['vertices']\n",
    "    center_x, center_y = calculate_center(vertices)\n",
    "    center_points_with_descriptions.append({'description': description, 'x': center_x, 'y': center_y})\n",
    "\n",
    "# Print the center points with descriptions\n",
    "print(json.dumps(center_points_with_descriptions, indent=2))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = center_points_with_descriptions\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a threshold for y values to consider them as belonging to the same row\n",
    "y_threshold = 50\n",
    "\n",
    "# Define the number of columns\n",
    "num_cols = 6\n",
    "\n",
    "# Calculate the bins for x based on the number of columns\n",
    "x_bins = np.linspace(df['x'].min(), df['x'].max(), num_cols + 1)\n",
    "\n",
    "# Assign each point to a cell in the table\n",
    "df['column'] = np.digitize(df['x'], x_bins) - 1\n",
    "\n",
    "# Create 'y_bins' using 'y_threshold'\n",
    "y_bins = np.arange(df['y'].min(), df['y'].max() + y_threshold, y_threshold)\n",
    "\n",
    "# Assign each point to a row in the table\n",
    "df['row'] = np.digitize(df['y'], y_bins) - 1\n",
    "\n",
    "# Calculate the number of rows dynamically based on the 'row' column\n",
    "num_rows = df['row'].max() + 1\n",
    "\n",
    "# Create a table with the specified number of rows and columns\n",
    "table = pd.DataFrame('', index=np.arange(num_rows), columns=np.arange(num_cols))\n",
    "\n",
    "# Fill the table with the descriptions from the data\n",
    "for i, row in df.iterrows():\n",
    "    table.at[row['row'], row['column']] = row['description']\n",
    "\n",
    "# Print the resulting table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0         1     2          3    4      5         6\n",
      "0   No.  Obtained   No.  Hobtained  No.  Marks  Obtained\n",
      "1                                                    NaN\n",
      "2    11         4    19                              NaN\n",
      "3                  21st              18              NaN\n",
      "4    on              11              19              NaN\n",
      "5                    12              20              NaN\n",
      "6                                                    NaN\n",
      "7     5              13              21              NaN\n",
      "8                    14              22              NaN\n",
      "9                                    23              NaN\n",
      "10   00              16              24              NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = center_points_with_descriptions\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a threshold for y values to consider them as belonging to the same row\n",
    "y_threshold = 50\n",
    "\n",
    "# Define the number of columns\n",
    "num_cols = 6\n",
    "\n",
    "# Calculate the bins for x based on the number of columns\n",
    "x_bins = np.linspace(df['x'].min(), df['x'].max(), num_cols + 1)\n",
    "\n",
    "# Assign each point to a cell in the table\n",
    "df['column'] = np.digitize(df['x'], x_bins) - 1\n",
    "\n",
    "# Create 'y_bins' using 'y_threshold'\n",
    "y_bins = np.arange(df['y'].min(), df['y'].max() + y_threshold, y_threshold)\n",
    "\n",
    "# Assign each point to a row in the table\n",
    "df['row'] = np.digitize(df['y'], y_bins) - 1\n",
    "\n",
    "# Calculate the number of rows dynamically based on the 'row' column\n",
    "num_rows = df['row'].max() + 1\n",
    "\n",
    "# Create a table with the specified number of rows and columns\n",
    "table = pd.DataFrame('', index=np.arange(num_rows), columns=np.arange(num_cols))\n",
    "\n",
    "# Fill the table with the descriptions from the data\n",
    "for i, row in df.iterrows():\n",
    "    table.at[row['row'], row['column']] = row['description']\n",
    "\n",
    "# Print the resulting table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image_path = 'b.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "    # Get the height and width of the image\n",
    "image_height, image_width, _ = image.shape\n",
    " # Height of the blank image\n",
    "blank_image = np.zeros((image_height, image_width, 3), np.uint8)\n",
    "\n",
    "# Draw circles and text on the blank image\n",
    "for point in center_points_with_descriptions:\n",
    "    x, y = int(point['x']), int(point['y'])\n",
    "    description = point['description']\n",
    "\n",
    "    # Draw text\n",
    "    cv2.putText(blank_image, description, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)  # Red text\n",
    "\n",
    "# Define the number of columns and draw vertical lines\n",
    "num_columns = 6  # Adjust this to match the number of columns in your data\n",
    "column_width = image_width // num_columns\n",
    "for i in range(1, num_columns):\n",
    "    x = i * column_width\n",
    "    cv2.line(blank_image, (x, 0), (x, image_height), (0, 0, 255), 2)  # Draw red vertical lines\n",
    "\n",
    "# Display or save the image\n",
    "cv2.imshow('Annotated Image', blank_image)\n",
    "cv2.waitKey(0)  # Wait until a key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image to a file\n",
    "cv2.imwrite('annotated_image.jpg', blank_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Example path, replace with your Tesseract path\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread('annotated_image.jpg')\n",
    "\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply adaptive thresholding to invert the image\n",
    "binary_thresh = cv2.adaptiveThreshold(~gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                      cv2.THRESH_BINARY, 15, -2)\n",
    "\n",
    "# Copy the binary image\n",
    "vertical = binary_thresh.copy()\n",
    "\n",
    "# Define the structure size for the vertical kernel\n",
    "vertical_size = vertical.shape[0] // 30\n",
    "\n",
    "# Create a vertical kernel\n",
    "vertical_structure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vertical_size))\n",
    "\n",
    "# Apply morphological operations\n",
    "vertical = cv2.erode(vertical, vertical_structure)\n",
    "vertical = cv2.dilate(vertical, vertical_structure)\n",
    "\n",
    "# Use pytesseract to extract text\n",
    "config = ('-l eng --oem 1 --psm 3')\n",
    "text = pytesseract.image_to_string(vertical)\n",
    "\n",
    "# Post-process the extracted text\n",
    "rows = text.split('\\n')\n",
    "table = [row.split() for row in rows]\n",
    "\n",
    "# Print the extracted table data\n",
    "for row in table:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Column1    Column2\n",
      "0   Question      Marks\n",
      "1        No.  Obtained}\n",
      "2          1         25\n",
      "3          2          3\n",
      "4          3         2.\n",
      "5          4          5\n",
      "6          5          5\n",
      "7          6         35\n",
      "8          7         45\n",
      "9        No,       None\n",
      "10        10       None\n",
      "11        Ww       None\n",
      "12        12       None\n",
      "13        13       None\n",
      "14        14       None\n",
      "15        15       None\n",
      "16        16       None\n",
      "17     Morks       None\n",
      "18    Obtait       None\n",
      "19  Question       None\n",
      "20       No.       None\n",
      "21        WW       None\n",
      "22        18       None\n",
      "23        19       None\n",
      "24         2       None\n",
      "25        24       None\n",
      "26     Morks       None\n",
      "27  Obtained       None\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Example path, replace with your Tesseract path\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread('annotated_image.jpg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding\n",
    "_, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find the contours\n",
    "contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter contours based on their area (you may need to adjust the value)\n",
    "contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 50]\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i, contour in enumerate(contours):\n",
    "    # Get the bounding rectangle for the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Slice the image using the bounding rectangle\n",
    "    roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "    # Extract text from the region of interest\n",
    "    text = pytesseract.image_to_string(roi)\n",
    "\n",
    "    # Split the text into lines and values\n",
    "    lines = text.splitlines()\n",
    "    values = [line.split() for line in lines if line.strip()]\n",
    "\n",
    "    # If values are less than expected, append None values to compensate\n",
    "    num_columns = len(values[0])  # Assuming the number of columns is the same for all rows\n",
    "    for value in values:\n",
    "        if len(value) < num_columns:\n",
    "            value += [None] * (num_columns - len(value))\n",
    "\n",
    "    # Append the values to the DataFrame\n",
    "    df_temp = pd.DataFrame(values, columns=[\"Column1\", \"Column2\"])\n",
    "    df = pd.concat([df, df_temp], ignore_index=True)\n",
    "\n",
    "# Specify the columns to keep (excluding the \"name\" column)\n",
    "columns_to_keep = [col for col in df.columns if col != 'name']\n",
    "\n",
    "# Create a new DataFrame with the desired columns\n",
    "df_cleaned = df[columns_to_keep]\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\freelancer\\student ocr\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
